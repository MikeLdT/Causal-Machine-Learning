---
title: "Tarea 4: Targeted Marketing"
author: "Jorge H, Alexa G, Adrián M, Miguel L, Carlos L."
date: "2021"
output: pdf_document
graphics: yes
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE,
                      fig.width = 6, fig.height = 4.5, fig.align = "right", cache = T)
options(digits = 6, scipen=999)
```

\setlength{\parskip}{6pt}


## Overview
Saludos
Los contratan como data scientists para una empresa que vende electrodomesticos. La empresa lanzó un experimento de control aleatorio via un mail en donde se envió un catalogo de los productos al grupo de tratamiento `mailing_indicator`. 

Tu objetivo es estimar el impacto del envío sobre el gasto incremental: 

$$\tau_{i}=\mathbb{E}[Y_{i}(1)-Y_{i}(0)|\boldsymbol{x}_{i}],$$

En particular, queremos estimar el impacto de enviar el catalogo a nivel de cliente. Para ello, pondremos a competir algunos de los modelo de Causal Machine Learning que hemos aprendido en clase: 

- Double Debiased Machine Learning 

- Causal Forests 

Adicionalmente, desarrollen una estrategia de focalización con base en los resultados de tu modelo. Elabora sobre la lógica económica (i.e. identifica los Beneficios y Costos Marginales de enviar la campaña). Finalmente, corrobora la validez externa de la estrategia usando datos de un año. Esto nos dará un termómetro de la utilidad del modelo para campañas posteriores. 

Tip!: En los chunks donde vaya a haber modelos o cálculos complicados, usen `cache=T`

## Paso 1: Estimación y predicción the Conditional Average Treatment Effects (CATE)

Carguemos los datos de 2015

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(data.table)
library(gamlr)
library(grf)
library(xgboost)
library(ranger)
library(RCT)
library(lfe)
library(stargazer)
library(knitr)
library(reshape2)
library(corrr)
library(kableExtra)
library(broom)
```

```{r}
ruta_trabajo <- "/Users/adrian_martinez/Dropbox/Maestría/Maestría Clases/Segundo_Semestre/economia_computacional/Causal-Machine-Learning"
setwd(ruta_trabajo)

load("Customer-Development-2015-1.RData")
```

Dividimos la base en entrenamiento y validacion. Usamos un seed fijo para replicabilidad.

```{r}
set.seed(1990)
crm <-
  crm %>% 
  mutate(training_sample = rbinom(n = nrow(crm), 1, 0.7))
  
```


#### Data cleaning

1. Haz una primera revisión de la base. Cuantas variables tienen `NA`

```{r}
x<-sapply(crm, function (x) sum(is.na(x)))

as.data.frame(x) %>% 
  filter(x>0)

#map(crm, ~sum(is.na(.)))

```
Hay múltiples variables con cero, pero ninguna variable tiene `NA`.


2. Muestra la matriz de correlación entre variables. Muestra los pares de variables que tienen más de 95% de correlación. Remueve una de cada par multicolineal. 

Mostramos un heatmap para todas las variables, para ilustrar la matriz de correlación entre variables.
```{r}
#Mapa de calor para matriz de correlaciones


mcor<-round(cor(crm),2)

melt_mcor<-melt(mcor)

heatmap_1<-ggplot(data = melt_mcor, aes(x=Var1, y=Var2, fill=value)) + 
 scale_fill_gradient2(low = "blue", high = "red")+
  geom_tile()+ 
 theme(axis.text.x = element_text(angle = 90, vjust = 1,size = 3, hjust = 1),axis.text.y = element_text(vjust = 1,size = 3, hjust = 1))

print(heatmap_1)
```

Los pares de variables que tienen más de 95% de correlación son:
```{r}
#Pares de variables con más de 95%:

res.cor <- correlate(crm)

corrs<-res.cor %>%  
    gather(-term, key = "colname", value = "cor") %>% 
    filter(abs(cor) > 0.95) %>%
    arrange(-abs(cor))

kable(corrs, caption = "Variables con una correlación elevada")%>%
  kable_classic(full_width = F, html_font = "Cambria")

```

Removemos una de cada par multicolineal:
```{r}


crm<-crm %>% 
  select(-customer_type_3, -orders_online_attributed_target, 
         -acquisition_months_since, -in_database_months, 
         -emails_days_2yr, -emailview_6m)

```


3 (2 pts). Corroba que la asignación tratamiento fue aleatoria mediante revisión del balance. Realiza las pruebas balance T y F. Cuántas variables salen desbalanceadas? Que muestra esto sobre la asignación de tratamiento?

```{r}
#Corremos las tablas de balance:
#bt <- balance_table(crm, "mailing_indicator")

# Guardar bt para no tener que volverlo a correr
# saveRDS(bt, "./bt.rds")

#br <- balance_regression(crm, "mailing_indicator")

# Guardar el br para no tener que volverlo a correr
# saveRDS(br, "./br.rds")


#Imprimimos las tablas de balance
br<-readRDS("br.rds")
bt<-readRDS("bt.rds")

kable(bt, caption = "Tabla de Balance") %>%
  kable_classic(full_width = F, html_font = "Cambria")

kable(br, caption = "Tabla de Balance Conjunta", digits = 4) %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
Número de variables desbalanceadas en la tabla de balance T:
```{r}
bt2<-bt %>% 
  filter(p_value1<0.05) %>% 
  summarise(total=n())

bt2
```

Número de variables desbalanceadas en la tabla de balance F (Conjunta):
```{r}
br2<-br$regression_tables %>% 
  filter(p.value<0.05) %>% 
  summarise(total=n())

br2
```

Entonces, al ser solamente `r bt2` variables de 149 en el caso de tabla de balance T y `r br2` variables de 149 en el caso de la tabla de balance F que salen deblanceadas, se puede concluir que, en general, existe un balance de la asignación de tratamiento.

4. Realize un ajuste de False Discovery Rate al 10%. Cuántas variables salen desbalanceadas ahora? 
```{r}
datos_pvalue <- br$regression_tables %>% 
  as.data.frame(.)
#Crear variable ranking:
datos_pvalue <- datos_pvalue %>%
  arrange(p.value) %>%
  mutate(ranking = row_number(p.value))

#Gráfica del FDR:
q <- 0.10
n <- max(datos_pvalue$ranking)

FDR <- ggplot(datos_pvalue,aes(x=ranking,y=p.value)) +
  geom_point(color="black") +
  geom_abline( aes(intercept = 0, slope = q/n,color="Ajuste FDR"), size=.6)+
  geom_abline(aes(intercept = 0.05, slope = 0, color="P-value=0.05"), size=.6)+
  ggtitle("Gráfica FDR") +
  theme_bw() +
  labs(color="Legend",title="")

print(FDR)


#Encontrar número de variables singificativas:
p_values_3 <- datos_pvalue%>%
 arrange(p.value) %>%
 mutate(ranking = row_number(p.value),
  alpha = q*ranking/n,
  signif_FDR = ifelse(alpha>=p.value,1,0),
  signif_0.05 = ifelse(0.05>=p.value,1,0))

#Número de variables significativas con FDR es:
num1 <- sum(p_values_3$signif_FDR)


```
Por lo tanto, el número de variables que salen desbalanceadas deacuerdo al FDR es `r num1`.


### Estimación de impacto de tratamiento (ATE)

5 (2pts). Estima el impacto promedio de enviar el catalogo vía email. Estima el impacto sin controles y luego agregar dos estimaciones de robustez: 1) Agregando variables que salieron significativas y 2) Agregando variables que salieron significativas con el FDR. Interpreta los resultados 


```{r}
ydep <- crm$outcome_spend


Mod1 <- lm(outcome_spend ~ mailing_indicator, data = crm)
 

coef_fdr <- p_values_3 %>% 
  filter(!term %in% c("(Intercept)","outcome_spend"), signif_FDR==1 ) %>% 
  pull(term)


coef_pval <- p_values_3 %>% 
  filter(!term %in% c("(Intercept)","outcome_spend"), signif_0.05==1 ) %>% 
  pull(term)

f <- as.formula(
  paste("ydep", 
        paste(coef_fdr, collapse = " + "), 
        sep = " ~ mailing_indicator+"))
g <- as.formula(
  paste("ydep", 
        paste(coef_pval, collapse = " + "), 
        sep = " ~ mailing_indicator+"))

#Variables significativas por FDR

Mod2 <- lm(f, data=crm)

#Variables significativas al 5%:
Mod3 <- lm(g, data=crm)


stargazer(Mod1,Mod2,Mod3, type = "text")

```
Tanto en la estimación sin controles como en ambas pruebas de robustez, se puede observar que enviar por correo un mensaje tiene un efecto positivo y significativo. Por lo tanto, sabemos que enviar un correo aumenta el gasto incremental en alrededor de $2.9. 

#### Estimación de efectos heterogéneos

Usaremos el training sample para estimar el Conditional Average Treatment Effect de enviar el catalogo sobre el gasto en dólares. Estimaremos dos tipos de modelos (si agregan otro es bienvenido): 

(a) Double Debiased LASSO
(b) Causal Forests 


\bigskip

Separa la base de entrenamiento de la de validación



#### Double Debiased LASSO

6 (3pts). Estima un Double Debiased LASSO. Asegurate de mostrar el código. (Tip: recuerda que necesitas guardar el LASSO de cada K para poder usarlo en la base de validación)

```{r}
#Dividimos la base en K=5 partes de forma aleatoria.
base_training <-crm %>% 
  filter(training_sample==1)
```

```{r}
lasso_treat <- vector(mode="list", length=5)
lasso_monto <- vector(mode="list", length=5)

base_training<-crm %>% 
  filter(training_sample==1)



base_training <-base_training%>% 
  arrange(mailing_indicator)

k<-treatment_assign(data = base_training, share_control = 0.2, n_t = 4, 
                    strata_varlist = "mailing_indicator",missfits = "global",
                    seed = 1900, key ="mailing_indicator")$data

k <- k%>% 
  mutate(k = treat+1) %>% 
  ungroup()

base_training<-bind_cols(base_training, k %>% select(k))

k<-k$k


monto_ret<-base_training$outcome_spend
treat<-base_training$mailing_indicator

X<-base_training %>% 
  select(-outcome_spend, -mailing_indicator,-k)


modelo<-map_dfr(1:5,
                function(a) {
                  
                  treat_fit <-gamlr(x = X[k!=a, , drop= F],
                              y = treat[k!=a], family="binomial") 
                  treat_hat<-as.numeric(predict(treat_fit, 
                                                newdata = X[k==a, , drop= F], 
                                                type = "response"))
                  lasso_treat[[a]] <<- treat_fit
                  
                  monto_fit <- gamlr(x = X[k!=a, , drop= F],
                                    y =  monto_ret[k!=a])
                  monto_hat <- as.numeric(predict(monto_fit,newdata = X[k==a, , 
                                                                        drop= F],
                                                  type ="response"))
                  lasso_monto[[a]] <<- monto_fit
      
                  treat_resid <- treat[k==a]-treat_hat
                  resid_monto <- monto_ret[k==a]-monto_hat
                  
                  fits<-bind_cols("treat_hat" = treat_hat,
                                  "monto_hat"= monto_hat,
                                  "resid_treat" = treat_resid,
                                  "resid_monto" = resid_monto)
                  })



```


7 (2pts). Cuál es el impacto de tratamiento promedio? Estimalo de dos maneras: 1) `spend_resid~treat_hat + treat` y 2) `spend~treat_resid`. Sale lo mismo? Justifica tu respuesta

```{r}
ef_prom_1 <- lm(resid_monto ~ treat_hat + treat,data = modelo)


ef_prom_2 <- lm(monto_hat~resid_treat,data = modelo)

ef_prom_3 <- lm(resid_monto~resid_treat,data = modelo)

stargazer(ef_prom_1,ef_prom_2,ef_prom_3,type="text")
```
FALTA INTERPRETACIÓN!!!


8 (3pts). Cuáles son las variables más importantes para las nuisance functions $T_i = g(X_i)+v_i$ y $y_i=m(X_i)+\epsilon_i$? (Tip: toma las variables que tengan $\beta \neq 0$ en cada $k$ y haz un `inner_join`. De ahí muestra el promedio de los coeficientes) Interpreta la función $g(X_i)$, porque sale así?


```{r}
coefs_treat<-lapply(lasso_treat, function(x) as.data.frame(as.matrix(coef(x)))) 
coefs_treat<-lapply(coefs_treat, function(x) x %>% filter(.!=0))

coefs_mont<-lapply(lasso_monto, function(x) as.data.frame(as.matrix(coef(x)))) 
coefs_mont<-lapply(coefs_mont, function(x) x %>% filter(.!=0))

for(i in 1:5){
  names(coefs_treat[[i]]) <- "Coeficientes"
  names(coefs_mont[[i]]) <- "Coeficientes"
  
  setDT(coefs_treat[[i]], keep.rownames = "Nombres")[]
  setDT(coefs_treat[[i]], keep.rownames = "Nombres")[]
  
}

union<-inner_join(coefs_treat[[1]],coefs_treat[[2]], by="Nombres")


for(i in 3:5){
  union<-inner_join(coefs_treat[[i]],union, by="Nombres")
}
```

Las variables que prevalecieron en los 5 modelos son:
```{r}
union$Nombres
```

La media de los valores que prevalecieron fue:
```{r}
mean(union$Coeficientes, union$Coeficientes.x.x, union$Coeficientes.y, union$Coeficientes.x, union$Coeficientes.y.y)

```
Después de correr los 5 modelos e identificar las variables relevantes en cada caso, únicamente el intercepto se repitió en los 5 casos (fue distinto a 0). Por lo tanto la función sería $g(X_i)=\beta_0$. (Quizá para no perder las variables relevantes de los modelos estimados, podríamos emplear un left_join en lugar del inner_join).


9 (3pts). Ahora corre un DDML LASSO para encontrar los efectos a nivel cliente (Tip: interactúa todas las variables con `treat_resid`. Muestra el código. Qué varaibles salen significativas?

```{r pregunta-9, echo = TRUE}
# Base de datos auxiliar
data_9 <- modelo %>% 
  bind_cols(base_training %>% select(-outcome_spend))

# Generamos los vectores/matrices para el lasso
resid_monto <- data_9$resid_monto
x <- sparse.model.matrix(~ resid_treat*.+ 0, 
                         data_9 %>% 
                    select(-resid_monto, -k, -customer_id, -training_sample, 
                           -treat_hat, -monto_hat, -mailing_indicator))

# Lasso
modelo_9 <- gamlr(y = resid_monto, x = x, family = "gaussian") 

```

```{r, results = "asis"}
# Variables que salieron significativas
as.data.frame(as.matrix(coef(modelo_9))) %>% 
  filter(seg100 != 0) %>% 
  arrange(-abs(seg100)) %>% 
  kable(., col.names = c("Coeficiente"), caption = "Variables Significativas")
```


10 (2 pts). Predice el CATE en la base de entrenamiento y en la base de validación. Como se ve la distribución del impacto de tratamiento en ambas? 

```{r}
# Calculamos los residuales en la base de validación
base_validacion <- crm %>% 
  filter(training_sample == 0) %>% 
   select(-outcome_spend, -mailing_indicator)

outcome_spend_validacion <- crm %>% 
  filter(training_sample == 0) %>% 
  pull(outcome_spend)

treat_validacion <- crm %>% 
  filter(training_sample == 0) %>% 
  pull(mailing_indicator)

# Residuales de monto/y
lasso_monto_validacion <- map_dfc(1:5, function(a){
  # Predecimos "y"
  monto_hat <- predict(lasso_monto[[a]], newdata = base_validacion)
  as.matrix(monto_hat)
})

# Residuales de treat
lasso_treat_validacion <- map_dfc(1:5, function(a){
  treat_hat <- predict(lasso_treat[[a]], newdata = base_validacion)
  as.matrix(treat_hat)
})

lasso_monto_validacion <- lasso_monto_validacion %>% 
  mutate(media = rowMeans(across()))

lasso_treat_validacion <- lasso_treat_validacion %>% 
  mutate(media = rowMeans(across()))

base_validacion <- base_validacion %>% 
  bind_cols(lasso_monto_validacion %>% 
              select(media) %>% 
              rename(media_monto = media)) %>% 
  bind_cols(lasso_treat_validacion %>% 
              select(media) %>% 
              rename(media_treat = media))

base_validacion$resid_treat <- treat_validacion - base_validacion$media_treat
base_validacion$resid_monto <- outcome_spend_validacion - base_validacion$media_monto

x_val <- base_validacion %>% 
  select(-resid_monto, -customer_id, -training_sample, -media_monto, 
         -media_treat)

x_val <- sparse.model.matrix(~ resid_treat*.+ 0, x_val)
resid_monto_val <- base_validacion$resid_monto

y_val_1 <- predict(modelo_9, newdata = x)
```


```{r}
# CATE entrenamiento
cate <- x[base_training$mailing_indicator == 1, grepl("resid", colnames(x))] %*% unlist(coef(modelo_9))[grepl("resid", rownames(coef(modelo_9))),]

# CATE validacion
cate_val <- x_val[treat_validacion == 1, grepl("resid", colnames(x_val))] %*% unlist(coef(modelo_9))[grepl("resid", rownames(coef(modelo_9))),]

# Transformamos de matrices a data frames para poder hacer los gráficos
cate_val <- as.data.frame(as.matrix(cate_val))
cate <- as.data.frame(as.matrix(cate)) 

label_cate <- paste0("ATE = ", round(mean(cate$V1),2))
label_cate_val <- paste0("ATE = ", round(mean(cate_val$V1),2))

cate %>% 
  ggplot(data = ., aes(x = V1)) +
  geom_histogram(color = "black", 
                 aes(y = ..density.., fill = "Training"),  alpha = 0.5) +
  geom_histogram(color = "black", data = cate_val, 
                 aes(y = ..density.., fill = "Validation"), alpha = 0.5) +
  geom_vline(aes(xintercept = mean(cate_val$V1), color = label_cate), linetype = "dashed") +
  geom_vline(aes(xintercept= mean(cate$V1), colour = label_cate_val), linetype = "dashed") +
  labs(x = "CATE", y = "Densidad", fill = "Base") +
  scale_color_manual(name = "Estadísticos", 
                     values = c("red",  "blue")) +
  theme_minimal()

```

#### Causal Forest

11 (2pts). Ahora vayamos al causal forest. Estima un causal forest en la base de entrenamiento (Estima 750 árboles)

```{r}
# Vector con el outcome
Y <- crm %>% filter(training_sample == 1) %>% 
  select(outcome_spend) %>% 
  pull()

# Matriz con las variables explicativas
X <- sparse.model.matrix(~.+0-outcome_spend-mailing_indicator,
                         data = crm %>%
                           filter(training_sample == 1)
                         )
# Vector con los tratamientos
W <- crm %>% filter(training_sample == 1) %>% 
  select(mailing_indicator) %>% 
  pull()

# Corremos el causal forest
#forest <- causal_forest(X = X, Y = Y, W = W, num.trees = 750)

# Guardar el causal forest para no tener que volverlo a correr
# saveRDS(forest, "./causal_forest.rds")
```

```{r}
forest <- readRDS("./causal_forest.rds")
ate <- average_treatment_effect(forest,
                                target.sample = "all", method = "AIPW")
```



12 (3pts). Cómo se distribuye el impacto de tratamiento? Cuál es el impacto de tratamiento (ATE)? Qué tanto se acerca al impacto de tratamiento "real"? Cómo se compara con el impacto estimado con el ddml simple?

```{r}
# Estimación del ATE "real"
ate_real <- base_training %>% 
  lm(data =., outcome_spend ~ mailing_indicator)

# Predecir el tau del causal forest
cate_causal_forest <- predict(forest)

# Generar deciles
cate_causal_forest <- cate_causal_forest %>% 
  mutate(decil = ntile(predictions, 10))

# Calcula el impacto promedio dentro de cada decil
tau_decil <- cate_causal_forest %>% group_by(decil) %>% 
  summarise(mean_decil = mean(predictions)) %>% 
  select(decil, mean_decil)

base_training$decil <- cate_causal_forest$decil

# Genera un data frame con el coeficiente estimado (ATE) para cada decil
coefs <- map_dfr(1:10, function(x){
  base_training %>% 
    filter(decil == {{x}}) %>% 
    lm(data = ., outcome_spend ~ mailing_indicator) %>% 
    coef()
}
)

# Label para el gráfico...
label_causal_forest_ate <- paste0("ATE = ", 
                                  round(mean(cate_causal_forest$predictions), 2))
label_real_ate <- paste0("ATE real = ", 
                                  round(ate_real$coefficients["mailing_indicator"], 2))

# Gráfico de la distribución del CATE y el ATE
cate_causal_forest %>% 
  ggplot(data = ., aes(x = predictions)) +
  geom_histogram(aes(y = ..density..), color = "black") +
  geom_vline(aes(xintercept = mean(cate_causal_forest$predictions), 
                 color = label_causal_forest_ate), linetype ="dashed") +
  geom_vline(aes(xintercept = ate_real$coefficients["mailing_indicator"], 
                 color = label_real_ate)) +
  scale_color_manual(name = "Estadisticos", values = c("red", "blue")) +
  theme_minimal()

```

En la gráfica anterior se puede observar la distribución del ATE gracias a los efectos heterogéneos. También se gráfican lineas verticales indicando el ATE estimado por causal forest y el ATE "real" que se obtiene de una regresión lineal entre la variable de interés y el tratamiento. Comparado con el ddml simple, la estimación del ATE es practicamente la misma, pues en el ddml simple se obtuve un ATE igual a 2.75. 

13. Haz un scatter plot de las predicciones de ambos modelos? Hay alguna relación?

```{r}

```


14 (4pts). Evalúa el poder predictivo de cada modelo (OOS). Esto se hace por modelo: Divide la muestra en 10 partes con base en el score de ddml. Para cada parte, estima el impacto de tratamiento vía una regresión y saca el promedio del score. Valida si para los grupos que dice el score el impacto será más grande, el coeficiente de la regresión es. Cómo se ven los modelos? Cuál parece ser mejor?


15 (6 pts). Construye una estrategia de focalización a nivel usuario con base a los resultados de cada modelo. Considera lo siguiente: 

- El costo marginal de mandar el mail es 0.99 USD 

- El Beneficio marginal es el impacto incremental la utilidad generada por esas ventas 

- El margen de ganancia sobre las ventas es de 32.5 fijo 

Con esto, indica: 

- Cuantos usuarios entrarían a la campaña? 

- A partir de cuánto lift (ventas incrementales) entran? 

- Cuál es el impacto promedio esperado de tu población final? 

- Cuánta utilidad haremos con esta estrategia? Cómo se compara con la utilidad de la campaña sin focalizar?

Campaña con base en el causal forest:

```{r}
# Sin focalizar
costo <- 250000 * 0.99
beneficio <- 2.74 * 250000 * .325
(utilidad_sin_focal <- beneficio - costo)

# Para el decil más alto
utilidad_decil <- map_dbl(1:10, function(x){
  n <- base_training %>% 
    count(decil) %>% 
    filter(decil == {{x}}) %>% 
    pull()
  
  costo <- n * 0.99
  
  tau <- tau_decil %>% 
    filter(decil == {{x}}) %>% 
    pull()
  
  beneficio <- tau * n * .325
  utilidad <- beneficio - costo
}
)


n_campana <- base_training %>% 
  count(decil) %>% 
  filter(decil >= 8) %>% 
  summarise(sum(.))

as.data.frame(utilidad_decil) %>% 
  mutate(decil = 1:10) %>% 
  kable(., col.names = c("Utilidad", "Decil"))
```

En la tabla anterior se puede observar que dado los parámetros que tenemos, a partir del decil 8 es cuando la empresa va a obtener beneficios de implementar la política de enviar un correo. La utilidad esperada de mandar los correos a partir del decil 8 sería de `r sum(utilidad_decil[8:10])`. Sin focalizar, la utilidad que se obtendría es negativa e igual a `r utiliad_sin_focal`. Por lo tanto, es necesario concentrarse solo en aquellos usuarios que reaccionan mucho ante la campaña. El número total de usuarios que entrarían a la campaña es de 52,491 individuos. 


16 (3pts). Haz una gráfica del la utilidad total vs q (personas que entran en la campaña) para DDML y CF

```{r}
# Gráfico de la utilidad del Causal Forest
utilidad <- cate_causal_forest %>% 
  arrange(-predictions) %>% 
  mutate(beneficio = predictions * .325, costo = 0.99) %>% 
  mutate(beneficio_total = cumsum(beneficio), costo_total = cumsum(costo)) %>% 
  mutate(utilidad = beneficio_total - costo_total) %>% 
  mutate(q = 1:n()) %>% 
  select(q, utilidad)
  

plot_utilidad <- utilidad %>% 
  ggplot(data = ., aes(x = q, y = utilidad)) +
  geom_line(size = 1, color = "blue") +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) +
  labs(x = "Personas que entran a la campaña") +
  annotate("point", x = 50328, y = 60852.9, color = "red") +
  theme_minimal()
    
plotly::ggplotly(plot_utilidad)
```

